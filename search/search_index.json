{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Database Migration Assessment","text":""},{"location":"#moving-database-workloads-to-google-cloud","title":"Moving Database Workloads to Google Cloud","text":"<ul> <li>Get the recommended Google Cloud configuration your current Oracle and SQL Server environments.</li> <li>Facts based approach to sizing that leverages metadata from your environment.</li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":"<p>Download the collection scripts from the latest release. Instructions for execution are included in the bundled README. * Oracle * MSSQL * Postgres * MySQL</p> <p>Instructions for execution are included in the README bundled with the collection scripts.</p>"},{"location":"code_of_conduct/","title":"Code of Conduct","text":""},{"location":"code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p>"},{"location":"code_of_conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to creating a positive environment include:</p> <ul> <li>Using welcoming and inclusive language</li> <li>Being respectful of differing viewpoints and experiences</li> <li>Gracefully accepting constructive criticism</li> <li>Focusing on what is best for the community</li> <li>Showing empathy towards other community members</li> </ul> <p>Examples of unacceptable behavior by participants include:</p> <ul> <li>The use of sexualized language or imagery and unwelcome sexual attention or     advances</li> <li>Trolling, insulting/derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or electronic     address, without explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a     professional setting</li> </ul>"},{"location":"code_of_conduct/#our-responsibilities","title":"Our Responsibilities","text":"<p>Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.</p> <p>Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.</p>"},{"location":"code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.</p> <p>This Code of Conduct also applies outside the project spaces when the Project Steward has a reasonable belief that an individual's behavior may have a negative impact on the project or its community.</p>"},{"location":"code_of_conduct/#conflict-resolution","title":"Conflict Resolution","text":"<p>We do not believe that all conflict is bad; healthy debate and disagreement often yield positive results. However, it is never okay to be disrespectful or to engage in behavior that violates the project\u2019s code of conduct.</p> <p>If you see someone violating the code of conduct, you are encouraged to address the behavior directly with those involved. Many issues can be resolved quickly and easily, and this gives people more control over the outcome of their dispute. If you are unable to resolve the matter for any reason, or if the behavior is threatening or harassing, report it. We are dedicated to providing an environment where participants feel welcome and safe.</p> <p>Reports should be directed to Cody Fincher codyfincher@google.com &amp; Warren Puziewicz warrenpuz@google.com, the Project Steward(s) for Database Migration Assessment framework. It is the Project Steward\u2019s duty to receive and address reported violations of the code of conduct. They will then work with a committee consisting of representatives from the Open Source Programs Office and the Google Open Source Strategy team. If for any reason you are uncomfortable reaching out to the Project Steward, please email opensource@google.com.</p> <p>We will investigate every complaint, but you may not receive a direct response. We will use our discretion in determining when and how to follow up on reported incidents, which may range from not taking action to permanent expulsion from the project and project-sponsored spaces. We will notify the accused of the report and provide them an opportunity to discuss it before any action is taken. The identity of the reporter will be omitted from the details of the report supplied to the accused. In potentially harmful situations, such as ongoing harassment or threats to anyone's safety, we may take action without notice.</p>"},{"location":"code_of_conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html</p>"},{"location":"contributing/","title":"How to Contribute","text":"<p>We'd love to accept your patches and contributions to this project. There are just a few small guidelines you need to follow.</p>"},{"location":"contributing/#contributor-license-agreement","title":"Contributor License Agreement","text":"<p>Contributions to this project must be accompanied by a Contributor License Agreement. You (or your employer) retain the copyright to your contribution; this simply gives us permission to use and redistribute your contributions as part of the project. Head over to https://cla.developers.google.com/ to see your current agreements on file or to sign a new one.</p> <p>You generally only need to submit a CLA once, so if you've already submitted one (even if it was for a different project), you probably don't need to do it again.</p>"},{"location":"contributing/#code-reviews","title":"Code Reviews","text":"<p>All submissions, including submissions by project members, require review. We use GitHub pull requests for this purpose. Consult GitHub Help for more information on using pull requests.</p>"},{"location":"contributing/#community-guidelines","title":"Community Guidelines","text":"<p>This project follows Google's Open Source Community Guidelines.</p>"},{"location":"developer_guide/commands/","title":"Commands","text":"<ul> <li> <p><code>make install</code> - Creates a new virtual environment for development.</p> </li> <li> <p><code>make clean</code> - Remove all build, testing, and static documentation files.</p> </li> <li> <p><code>make build</code> - Build a folder containing a set of the latest database collection scripts.</p> </li> <li> <p><code>make gen-docs</code> - Generate HTML documentation.</p> </li> <li> <p><code>make docs</code> - Generate HTML documentation and serve it to the browser.</p> </li> <li> <p><code>make pre-release increment={major/minor/patch}</code> - Bump the version and create a release tag. Should only be run from the main branch. Passes the increment value to bump2version to create a new version number dynamically. The new version number will be added to __version__.py and pyproject.toml and a new commit will be logged. The tag will be created from the new commit.</p> </li> </ul>"},{"location":"developer_guide/developer_setup/","title":"Developer Setup","text":"<p>To begin local development, clone the GoogleCloudPlatform/database-assessment repository and use one of the following methods to build it. All commands should be executed from inside of the project home folder.</p>"},{"location":"developer_guide/developer_setup/#configure-environment","title":"Configure environment","text":"<pre><code>make install\n</code></pre>"},{"location":"developer_guide/releases/","title":"Releases","text":"<p>A release should consist of the following two steps from a tested, linted, and up to date copy of the main branch:</p> <ol> <li> <p><code>make pre-release increment={major/minor/patch}</code> - Commit the version number bump and create a new tag locally. The version number follows semantic versioning standards (major.minor.patch) and the tag is the version number prepended with a 'v'.</p> </li> <li> <p><code>git push --follow-tags</code> - Update the main branch with only the changes from the version bump. Publish the new tag and kick off the release workflow.</p> </li> </ol>"},{"location":"developer_guide/workflows/","title":"Workflows","text":""},{"location":"developer_guide/workflows/#release","title":"Release","text":"<ul> <li>Linting and testing steps must pass before the release steps can begin.</li> <li>Documentation is automatically published to the <code>gh-pages</code> branch and hosted on github pages.</li> <li>All github release tags, docker image tags, and PyPI version numbers are in agreement with one another and follow semantic versioning standards.</li> <li>Builds collections packages and attaches to release</li> </ul>"},{"location":"developer_guide/workflows/#build-and-publish-docs","title":"Build and Publish Docs","text":"<ul> <li>Build the documentation, publish to the <code>gh-pages</code> branch, and release to github pages.</li> <li>Runs only on a manual trigger in the github actions tab.</li> </ul>"},{"location":"user_guide/mysql/collection_scripts/","title":"Gather workload metadata","text":"<p>The workload collection supports MySQL 5.6 and newer. Older versions of MySQL are not currently supported.  MariaDB is also not currently supported with this version of the script.</p>"},{"location":"user_guide/mysql/collection_scripts/#system-environment","title":"System environment","text":"<p>The collection script is designed to run in a Unix or Unix-like environment. It can be run on Windows within either Windows subsystem for Linux or Cygwin. It depends on the following to be available on the machine from which it is run:</p> <pre><code>bash shell\ncat\ncut\ndirname\ngrep\nlocale\nmkdir\nmysql\nsed\ntar\ntr\nwhich\nzip or gzip\n</code></pre>"},{"location":"user_guide/mysql/collection_scripts/#execute-collection-script","title":"Execute collection script","text":"<p>Download the latest collection scripts here.</p> <pre><code>mkdir ./dbma_collector &amp;&amp; cd dbma_collector\nwget https://github.com/GoogleCloudPlatform/database-assessment/releases/latest/download/db-migration-assessment-collection-scripts-mysql.zip\nunzip db-migration-assessment-collection-scripts-mysql.zip\n</code></pre> <ul> <li>Execute this from a system that can access your database via mysql command line client.</li> </ul> <p>Execute the collection script with connection parameters:</p> <pre><code>    ./collect-data.sh --collectionUserName root --collectionUserPass secret --hostName myhost.example.com --port 25432 --databaseService sys --vmUserName myuser --extraSSHArg \"-p\" --extraSSHA\nrg \"12248\"\n</code></pre> <p>The example above will connect to a database named 'sys' on host myhost.example.com on port 25432 as user \"root\" with password \"secret\".  It will also ssh as the current user to myhost.example.com, port 12248 to collect information on about the machine running the database.   - Parameters</p> <pre><code> Connection definition must one of:\n      {\n        --connectionStr       Connection string formatted as {user}/{password}@//{db host}:{listener port}/{service name}\n       or\n        --hostName            Database server host name\n        --port                Database listener port\n        --databaseService     Database service name\n        --collectionUserName  Database user name\n        --collectionUserPass  Database password\n      }\n\n  Additional Parameters:\n        --manualUniqueId      (Optional) A short string to be attached to this collection.  Use only when directed.\n\n  VM collection definition (optional):\n        --vmUserName          Username for the ssh session to --hostName for collecting machine information.\n        --extraSSHArg         Extra args to be passed as is to ssh. Can be specified multiple times or as a single quoted string..\n\n</code></pre> <p>Examples:</p> <pre><code>To collect data for a single database:\n  ./collect-data.sh --connectionStr {user}/{password}@//{db host}:{listener port}/{service name}\n or\n  ./collect-data.sh --collectionUserName {user} --collectionUserPass {password} --hostName {db host} --port {listener port} --databaseService {service name}\n\n To collect data for all databases in the instance:\n  ./collect-data.sh --connectionStr {user}/{password}@//{db host}:{listener port}\n or\n  ./collect-data.sh --collectionUserName {user} --collectionUserPass {password} --hostName {db host} --port {listener port}\n</code></pre>"},{"location":"user_guide/mysql/collection_scripts/#upload-collections","title":"Upload Collections","text":"<p>Upon completion, the tool will automatically create an archive of the extracted metrics that can be uploaded into the assessment tool.</p>"},{"location":"user_guide/oracle/collection_masker/","title":"Masking a collection","text":"<p>While the collection script does not gather any data or source code, it does contain the name of schemas and hostname information. If there is a requirement to obfuscate this data, there is an optional masking script included with the scripts.</p> <p>This one-way script will create a key file that maps the anonymized schema and hostname attributes to its original name.  This anonymized data can not be reversed in any way and requires the key to be decoded.  It currently is only supported for Oracle database collections.</p> <p>Note This file should not be sent with the collection and should not be lost, as it can't be recreated.</p>"},{"location":"user_guide/oracle/collection_masker/#executing-the-script","title":"Executing the script","text":"<p>The script can be executed at the shell or command prompt and requires 2 parameters:</p> <ul> <li>Path containing the collection archives you would like to mask. You should place the entire <code>zip</code> or <code>tar.gz</code> file in this folder, and you can include multiple collections with a single execution of the tool.</li> <li>Output directory is the path to write the masked collection archive.</li> </ul> <pre><code>$ ./masker/dma-collection-masker\nusage: dma-collection-masker [-h] [--verbose]\n  [--collection-path COLLECTION_PATH] [--output-path OUTPUT_PATH]\n\nGoogle Database Migration Assessment - Collection Masking Script\n\noptions:\n  -h, --help            show this help message and exit\n  --verbose, -v         Logging level: 0: ERROR, 1: INFO, 2: DEBUG\n  --collection-path COLLECTION_PATH\n                        Path to search for collections.\n  --output-path OUTPUT_PATH\n                        Path to write masked collections.\n</code></pre>"},{"location":"user_guide/oracle/collection_masker/#installation-note","title":"Installation Note","text":"<p>The only requirement this script has is the <code>packaging</code> Python repository.  This is likely already installed in your environment as it is part of many core packages.</p> <p>However, if you receive an error related to importing this package, please run:</p> <pre><code>pip install -U packaging\n</code></pre>"},{"location":"user_guide/oracle/collection_scripts/","title":"Gather workload metadata","text":"<p>The workload collection supports Oracle 10gR1 and newer. Older versions of Oracle are not currently supported.</p>"},{"location":"user_guide/oracle/collection_scripts/#system-environment","title":"System environment","text":"<p>The collection script is designed to run in a Unix or Unix-like environment. It can be run on Windows within either Windows subsystem for Linux or Cygwin. It depends on the following to be available on the machine from which it is run:</p> <pre><code>bash shell\ncat\ncut\ndirname\ngrep\nlocale\nmkdir\nsed\nsqlplus\ntar\ntr\nwhich\nzip or gzip\n</code></pre>"},{"location":"user_guide/oracle/collection_scripts/#execute-collection-script","title":"Execute collection script","text":"<p>Download the latest collection scripts here.</p> <pre><code>mkdir ./dbma_collector &amp;&amp; cd dbma_collector\nwget https://github.com/GoogleCloudPlatform/database-assessment/releases/latest/download/db-migration-assessment-collection-scripts-oracle.zip\nunzip db-migration-assessment-collection-scripts-oracle.zip\n</code></pre> <ul> <li>Execute this from a system that can access your database via sqlplus</li> <li>Execute from a user with DBA privileges or optionally use the provided creation script</li> </ul> <p>If the extract will be run by a user that does not have SYSDBA privilege, connect to the database as a user with SYSDBA privileges and create the user if needed. If this is a multi-tenant database, create the user as a common user in the root container. The Dma_collector does not currently support running in individual pluggable databases.</p> <p>For non-CDB databases:</p> <pre><code>sqlplus \"sys/password@//hostname:port/dbservicename as sysdba\"\nSQL&gt; create user DMA_COLLECTOR identified by password;\nSQL&gt; grant connect, create session to DMA_COLLECTOR;\n</code></pre> <p>For multitenant databases:</p> <pre><code>sqlplus \"sys/password@//hostname:port/dbservicename as sysdba\"\nSQL&gt; create user C##DMA_COLLECTOR identified by password;\nSQL&gt; grant connect, create session to C##DMA_COLLECTOR;\n</code></pre> <p>Navigate to the sql/setup directory and execute grants_wrapper.sql as a user with SYSDBA privileges. You will be prompted for the name of a database user (Note that input is case-sensitive and must match the username created above) to be granted privileges on the objects required for data collection. You will also be prompted whether or not to allow access to the AWR data. Access will be granted to Statspack tables if they are present.</p> <p>For non-CDB databases:</p> <pre><code>SQL&gt; @grants_wrapper.sql\nSQL&gt; Please enter the DB Local Username(Or CDB Username) to receive all required grants: DMA_COLLECTOR\nSQL&gt; Please enter Y or N to allow or disallow use of the Tuning and Diagnostic Pack (AWR) data (Y) Y\n</code></pre> <p>For multitenant databases:</p> <pre><code>SQL&gt; @grants_wrapper.sql\nSQL&gt; Please enter the DB Local Username(Or CDB Username) to receive all required grants: C##DMA_COLLECTOR\nSQL&gt; Please enter Y or N to allow or disallow use of the Tuning and Diagnostic Pack (AWR) data (Y) Y\n</code></pre> <p>The grant_wrapper script will grant privileges required and will output a list of what has been granted.</p> <p>Launch the collection script: (Note that the parameter names have changed from earlier versions of the collector)</p> <ul> <li>NOTE: If this is an Oracle RAC and/or PDB environment you just need to run it once per database. No need to run in each PDB or in each Oracle RAC instance.</li> <li>If you are licensed for the Oracle Tuning and Diagnostics packs, pass the parameter UseDiagnostics to use the AWR data.</li> <li> <p>If you are NOT licensed for the Oracle Tuning and Diagnostics packs, pass the parameter NoDiagnostics to exclude the AWR data. The script will attempt to use STATSPACK data if available.</p> </li> <li> <p>Parameters</p> </li> </ul> <pre><code> Connection definition must one of:\n    {\n       --connectionStr       Oracle EasyConnect string formatted as {user}/{password}@//{db host}:{listener port}/{service name}\n     or\n       --hostName            Database server hostname\n       --port                Listener port\n       --databaseService     Database service name\n       --collectionUserName  Database username\n       --collectionUserPass  Database password\n    }\n Performance statistics source\n     --statsSrc              Required. Must be one of AWR, STATSPACK, NONE.  When using STATSPACK, see note about --statsWindow parameter below.\n Performance statistics window\n     --statsWindow           Optional. Number of days of performance stats to collect.  Must be one of 7, 30.  Default is 30.\n                             NOTE: IF STATSPACK HAS LESS THAN 30 DAYS OF COLLECTION DATA, SET THIS PARAMETER TO 7 TO LIMIT TO 1 WEEK OF COLLECTION.\n                             IF STATSPACK HAS BEEN ACTIVATED SPECIFICALLY FOR DMA COLLECTION, ENSURE THERE ARE AT LEAST 8\n                             CALENDAR DAYS OF COLLECTION BEFORE RUNNING THE DMA COLLECTOR.\n\n\n NOTE: If using an Oracle auto-login wallet, specify the tns alias as the connection string:\n  Ex:\n    ./collect-data.sh --connectionStr /@mywalletalias --statsSrc AWR\n</code></pre> <p>To use the licensed Oracle Tuning and Diagnostics pack data:</p> <pre><code>./collect-data.sh --connectionStr {user}/{password}@//{db host}:{listener port}/{service name} --statsSrc AWR\nor\n./collect-data.sh --collectionUserName {user} --collectionUserPass {password} --hostName {db host} --port {listener port} --databaseService {service name} --statsSrc AWR\n\nex:\n\n./collect-data.sh --connectionStr MyUser/MyPassword@//dbhost.company.com:1521/MyDbName.company.com --statsSrc AWR\nor\n./collect-data.sh --collectionUserName MyUser --collectionUserPass MyPassword --hostName dbhost.company.com --port 1521 --databaseService MyDbName.company.com --statsSrc AWR\n</code></pre> <p>OR To avoid using the licensed Oracle Tuning and Diagnostics pack data:</p> <pre><code>./collect-data.sh --connectionStr {user}/{password}@//{db hosti}:{listener port}/{service name} --statsSrc STATSPACK\nor\n./collect-data.sh --collectionUserName {user} --collectionUserPass {password} --hostName {db host} --port {listener port} --databaseService {service name} --statsSrc STATSPACK\n\nex:\n\n./collect-data.sh --connectionStr MyUser/MyPassword@//dbhost.company.com:1521/MyDbName.company.com --statsSrc STATSPACK\nor\n./collect-data.sh --collectionUserName MyUser --collectionUserPass MyPassword --hostName dbhost.company.com --port 1521 --databaseService MyDbName.company.com --statsSrc STATSPACK\n\n\nIf Statspack has less than 30 days of data, limit collection to the last 7 days using the paramter --statsWindow:\n\n./collect-data.sh --connectionStr MyUser/MyPassword@//dbhost.company.com:1521/MyDbName.company.com --statsSrc STATSPACK --statsWindow 7\nor\n./collect-data.sh --collectionUserName MyUser --collectionUserPass MyPassword --hostName dbhost.company.com --port 1521 --databaseService MyDbName.company.com --statsSrc STATSPACK --statsWindow 7\n</code></pre> <p>Collections can be run as SYS if needed by setting ORACLE_SID and running on the database host:</p> <pre><code>./collect-data.sh --connectionStr '/ as sysdba' --statsSrc AWR\n</code></pre> <p>OR To avoid using the licensed Oracle Tuning and Diagnostics pack data:</p> <pre><code>./collect-data.sh  --connectionStr '/ as sysdba' --statsSrc STATSPACK\n</code></pre>"},{"location":"user_guide/oracle/collection_scripts/#upload-collections","title":"Upload Collections","text":"<p>Upon completion, the tool will automatically create an archive of the extracted metrics that can be uploaded into the assessment tool.</p>"},{"location":"user_guide/oracle/db_user_create/","title":"Database User Scripts (Optional)","text":"<p>The collection scripts can be executed with any DBA account. Alternately, a new user with the minimum privileges required for access with the following steps.</p>"},{"location":"user_guide/oracle/db_user_create/#create-user","title":"Create User","text":""},{"location":"user_guide/oracle/db_user_create/#non-container-database","title":"Non-container database","text":"<pre><code>create user dmacollector identified by \"Pa55w__rd123\";\ngrant connect, create session to dmacollector;\n</code></pre>"},{"location":"user_guide/oracle/db_user_create/#container-database","title":"Container database","text":"<pre><code>select * from v$system_parameter where name='common_user_prefix';\n--C##\ncreate user c##dmacollector identified by \"Pa55w__rd123\";\ngrant connect, create session to c##dmacollector;\n</code></pre>"},{"location":"user_guide/oracle/db_user_create/#grants","title":"Grants","text":"<p>From the directory you extracted the collector scripts, change to the sql/setup directory:</p> <pre><code>cd sql/setup\n</code></pre> <p>Execute the grants_wrapper script</p> <pre><code>@grants_wrapper.sql\n-- It will prompt for the user created above (Note that input is case-sensitive and must match the username created above).\n-- You will also be prompted whether or not to allow access to the AWR data.\n</code></pre> <p>AWR is a licensed feature of Oracle. If you don't have license to run AWR you can answer \"N\" to the above prompt and it will exclude the AWR data from collection.  If STATSPACK data is available, it will use that instead.</p>"},{"location":"user_guide/oracle/permissions/","title":"Create a user for Collection","text":"<p>The collection scripts can be executed with any DBA account. Alternatively, create a new user with the minimum privileges required. The included script sql/setup/grants_wrapper.sql will grant the privileges listed below. Please see the Database User Scripts page for information on how to create the user.</p>"},{"location":"user_guide/oracle/permissions/#permissions-required","title":"Permissions Required","text":"<p>The following permissions are required for the script execution:</p> <pre><code>  SELECT ON SYS.CDB_HIST_ACTIVE_SESS_HISTORY\n  SELECT ON SYS.CDB_HIST_OSSTAT\n  SELECT ON SYS.CDB_HIST_SNAPSHOT\n  SELECT ON SYS.CDB_HIST_SQLSTAT\n  SELECT ON SYS.CDB_HIST_SQLTEXT\n  SELECT ON SYS.CDB_HIST_SYSMETRIC_HISTORY\n  SELECT ON SYS.CDB_HIST_SYSMETRIC_SUMMARY\n  SELECT ON SYS.CDB_HIST_SYSSTAT\n  SELECT ON SYS.CDB_HIST_SYSTEM_EVENT\n  SELECT ON SYS.CDB_HIST_SYS_TIME_MODEL\n  SELECT ON SYS.DBA_HIST_ACTIVE_SESS_HISTORY\n  SELECT ON SYS.DBA_HIST_OSSTAT\n  SELECT ON SYS.DBA_HIST_SNAPSHOT\n  SELECT ON SYS.DBA_HIST_SQLSTAT\n  SELECT ON SYS.DBA_HIST_SQLTEXT\n  SELECT ON SYS.DBA_HIST_SYSMETRIC_HISTORY\n  SELECT ON SYS.DBA_HIST_SYSMETRIC_SUMMARY\n  SELECT ON SYS.DBA_HIST_SYSSTAT\n  SELECT ON SYS.DBA_HIST_SYSTEM_EVENT\n  SELECT ON SYS.DBA_HIST_SYS_TIME_MODEL\n  EXECUTE ON SYS.DBMS_UMF\n  EXECUTE ON SYS.DBMS_QOPATCH\n  SELECT ON PERFSTAT.STATS$OSSTATNAME\n  SELECT ON PERFSTAT.STATS$OSSTAT\n  SELECT ON PERFSTAT.STATS$SNAPSHOT\n  SELECT ON PERFSTAT.STATS$SQL_SUMMARY\n  SELECT ON PERFSTAT.STATS$SYSSTAT\n  SELECT ON PERFSTAT.STATS$SYSTEM_EVENT\n  SELECT ON PERFSTAT.STATS$SYS_TIME_MODEL\n  SELECT ON PERFSTAT.STATS$TIME_MODEL_STATNAME\n  SELECT ON SYS.AUX_STATS$\n  SELECT ON SYS.CDB_CONSTRAINTS\n  SELECT ON SYS.CDB_CPU_USAGE_STATISTICS\n  SELECT ON SYS.CDB_DATA_FILES\n  SELECT ON SYS.CDB_DB_LINKS\n  SELECT ON SYS.CDB_EXTERNAL_TABLES\n  SELECT ON SYS.CDB_FEATURE_USAGE_STATISTICS\n  SELECT ON SYS.CDB_FREE_SPACE\n  SELECT ON SYS.CDB_HIGH_WATER_MARK_STATISTICS\n  SELECT ON SYS.CDB_INDEXES\n  SELECT ON SYS.CDB_LOB_PARTITIONS\n  SELECT ON SYS.CDB_LOBS\n  SELECT ON SYS.CDB_LOB_SUBPARTITIONS\n  SELECT ON SYS.CDB_MVIEWS\n  SELECT ON SYS.CDB_OBJECTS\n  SELECT ON SYS.CDB_OBJECT_TABLES\n  SELECT ON SYS.CDB_PART_TABLES\n  SELECT ON SYS.CDB_PDBS\n  SELECT ON SYS.CDB_SEGMENTS\n  SELECT ON SYS.CDB_SERVICES\n  SELECT ON SYS.CDB_SOURCE\n  SELECT ON SYS.CDB_SYNONYMS\n  SELECT ON SYS.CDB_TAB_COLS\n  SELECT ON SYS.CDB_TAB_COLUMNS\n  SELECT ON SYS.CDB_TABLESPACES\n  SELECT ON SYS.CDB_TABLES\n  SELECT ON SYS.CDB_TAB_PARTITIONS\n  SELECT ON SYS.CDB_TAB_SUBPARTITIONS\n  SELECT ON SYS.CDB_TEMP_FILES\n  SELECT ON SYS.CDB_TRIGGERS\n  SELECT ON SYS.CDB_USERS\n  SELECT ON SYS.CDB_VIEWS\n  SELECT ON SYS.CDB_XML_TABLES\n  SELECT ON SYS.CONTAINER$\n  SELECT ON SYS.DBA_CONSTRAINTS\n  SELECT ON SYS.DBA_CPU_USAGE_STATISTICS\n  SELECT ON SYS.DBA_DATA_FILES\n  SELECT ON SYS.DBA_DB_LINKS\n  SELECT ON SYS.DBA_EXTERNAL_TABLES\n  SELECT ON SYS.DBA_FEATURE_USAGE_STATISTICS\n  SELECT ON SYS.DBA_FREE_SPACE\n  SELECT ON SYS.DBA_HIGH_WATER_MARK_STATISTICS\n  SELECT ON SYS.DBA_INDEXES\n  SELECT ON SYS.DBA_LOB_PARTITIONS\n  SELECT ON SYS.DBA_LOBS\n  SELECT ON SYS.DBA_LOB_SUBPARTITIONS\n  SELECT ON SYS.DBA_MVIEWS\n  SELECT ON SYS.DBA_OBJECTS\n  SELECT ON SYS.DBA_OBJECT_TABLES\n  SELECT ON SYS.DBA_PART_TABLES\n  SELECT ON SYS.DBA_REGISTRY_SQLPATCH\n  SELECT ON SYS.DBA_SEGMENTS\n  SELECT ON SYS.DBA_SERVICES\n  SELECT ON SYS.DBA_SOURCE\n  SELECT ON SYS.DBA_SYNONYMS\n  SELECT ON SYS.DBA_TAB_COLS\n  SELECT ON SYS.DBA_TAB_COLUMNS\n  SELECT ON SYS.DBA_TABLESPACES\n  SELECT ON SYS.DBA_TABLES\n  SELECT ON SYS.DBA_TAB_PARTITIONS\n  SELECT ON SYS.DBA_TAB_SUBPARTITIONS\n  SELECT ON SYS.DBA_TEMP_FILES\n  SELECT ON SYS.DBA_TRIGGERS\n  SELECT ON SYS.DBA_USERS\n  SELECT ON SYS.DBA_VIEWS\n  SELECT ON SYS.DBA_XML_TABLES\n  SELECT ON SYS.GV_$ARCHIVE_DEST\n  SELECT ON SYS.GV_$ARCHIVED_LOG\n  SELECT ON SYS.GV_$DATABASE\n  SELECT ON SYS.GV_$INSTANCE\n  SELECT ON SYS.GV_$PARAMETER\n  SELECT ON SYS.GV_$PDBS\n  SELECT ON SYS.GV_$PGASTAT\n  SELECT ON SYS.GV_$PROCESS\n  SELECT ON SYS.GV_$SGASTAT\n  SELECT ON SYS.GV_$SYSTEM_PARAMETER\n  SELECT ON SYS.NLS_DATABASE_PARAMETERS\n  SELECT ON SYS.OBJ$\n  SELECT ON SYS.REGISTRY$HISTORY\n  SELECT ON SYS.V_$ARCHIVE_DEST\n  SELECT ON SYS.V_$DATABASE\n  SELECT ON SYS.V_$EVENT_NAME\n  SELECT ON SYS.V_$INSTANCE\n  SELECT ON SYS.V_$LOGFILE\n  SELECT ON SYS.V_$LOG_HISTORY\n  SELECT ON SYS.V_$LOG\n  SELECT ON SYS.V_$PARAMETER\n  SELECT ON SYS.V_$PDBS\n  SELECT ON SYS.V_$PGASTAT\n  SELECT ON SYS.V_$RMAN_BACKUP_JOB_DETAILS\n  SELECT ON SYS.V_$SGASTAT\n  SELECT ON SYS.V_$SQLCOMMAND\n  SELECT ON SYS.V_$SYSTEM_PARAMETER\n  SELECT ON SYS.V_$TEMP_SPACE_HEADER\n  SELECT ON SYS.V_$VERSION\n  SELECT ON SYSTEM.LOGSTDBY$SKIP_SUPPORT\n</code></pre>"},{"location":"user_guide/postgres/collection_scripts/","title":"Gather workload metadata","text":"<p>The workload collection supports Postgres 12 and newer. Older versions of Postgres are not currently supported.</p>"},{"location":"user_guide/postgres/collection_scripts/#system-environment","title":"System environment","text":"<p>The collection script is designed to run in a Unix or Unix-like environment. It can be run on Windows within either Windows subsystem for Linux or Cygwin. It depends on the following to be available on the machine from which it is run:</p> <pre><code>bash shell\ncat\ncut\ndirname\ngrep\nlocale\nmkdir\npsql\nsed\ntar\ntr\nwhich\nzip or gzip\n</code></pre>"},{"location":"user_guide/postgres/collection_scripts/#execute-collection-script","title":"Execute collection script","text":"<p>Download the latest collection scripts here.</p> <pre><code>mkdir ./dbma_collector &amp;&amp; cd dbma_collector\nwget https://github.com/GoogleCloudPlatform/database-assessment/releases/latest/download/db-migration-assessment-collection-scripts-postgres.zip\nunzip db-migration-assessment-collection-scripts-postgres.zip\n</code></pre> <ul> <li> <p>Execute this from a system that can access your database via psql</p> </li> <li> <p>NOTE: The collector can be run for a single database or all databases in the instance.</p> </li> </ul> <p>Execute the collection script with connection parameters:</p> <pre><code>    ./collect-data.sh --collectionUserName postgres --collectionUserPass secret --hostName myhost.example.com --port 25432 --vmUserName myuser --extraSSHArg -p --extraSSHArg 12248\n</code></pre> <p>The example above will connect to a database named 'postgres' (the default) on host myhost.example.com on port 25432 as user \"postgres\" with password \"secret\".  It will also ssh as the current user to myhost.example.com, port 12248 to collect information on about the machine running the database.   - Parameters</p> <pre><code> Connection definition must one of:\n      {\n        --connectionStr       Connection string formatted as {user}/{password}@//{db host}:{listener port}/{service name}\n       or\n        --hostName            Database server host name\n        --port                Database listener port\n        --databaseService     Database service name (Optional. Defaults to 'postgres'.)\n        --collectionUserName  Database user name.\n        --collectionUserPass  Database password\n      }\n\n  Additional Parameters:\n        --allDbs              Collect data for all databases (Y/N).  Optional. Defaults to 'Y'.  Set to N to collect for only the database service given.\n        --manualUniqueId      (Optional) A short string to be attached to this collection.  Use only when directed.\n\n  VM collection definition (optional):\n        --vmUserName          Username for the ssh session to --hostName for collecting machine information.\n                              Must be supplied to collect hardware configuration of the database server if\n                              the collection script is not run dirctly on the database server.\n        --extraSSHArg         Extra args to be passed as is to ssh. Can be specified multiple times or as a single quoted string..\n\n</code></pre> <p>Examples:</p> <pre><code>To collect data for a single database:\n  ./collect-data.sh --connectionStr {user}/{password}@//{db host}:{listener port}/{service name} --allDbs N\n or\n  ./collect-data.sh --collectionUserName {user} --collectionUserPass {password} --hostName {db host} --port {listener port} --databaseService {service name} --allDbs N\n\n To collect data for all databases in the instance:\n  ./collect-data.sh --connectionStr {user}/{password}@//{db host}:{listener port}/{service name}\n or\n  ./collect-data.sh --collectionUserName {user} --collectionUserPass {password} --hostName {db host} --port {listener port} --databaseService {service name}\n</code></pre>"},{"location":"user_guide/postgres/collection_scripts/#upload-collections","title":"Upload Collections","text":"<p>Upon completion, the tool will automatically create an archive of the extracted metrics that can be uploaded into the assessment tool. One ZIP file will be created per database.</p>"},{"location":"user_guide/sqlserver/collection_scripts/","title":"Google Cloud Database Migration Assessment for Microsoft SQL Server","text":"<p>Instructions on how to prepare and run Google Database Migration Assessment Data Extractor for Microsoft SQL Server to extract the data required for analysis by the Database Migration Assessment tool.</p> <p>These scripts have been tested with the following platforms:</p> <p>SQL Server Versions:</p> <ul> <li>SQL Server 2008R2 SP2 through SQL Server 2022</li> <li>AZURE SQL Database</li> </ul> <p>Operating System Versions:</p> <ul> <li>Windows Server 2012 through Windows Server 2022 (Requires PowerShell Version 5 or Greater)</li> </ul>"},{"location":"user_guide/sqlserver/collection_scripts/#introduction","title":"Introduction","text":"<p>This utility extracts metadata about the tables, partitions and SQL workload in a database into CSV files. It also leverages perfmon data that must have a perfmon counter started before the final data collection. These CSV files are then used by Database Migration Assessment internally to analyze the data with Google Database Migration Assessment.</p>"},{"location":"user_guide/sqlserver/collection_scripts/#license-requirements","title":"License Requirements","text":"<p>!!! IMPORTANT Google Database Migration Assessment does not require any additional licensing with regards to Microsoft SQL Server.</p>"},{"location":"user_guide/sqlserver/collection_scripts/#database-privileges","title":"Database Privileges","text":"<p>This utility must be run as a database user with privileges to SELECT from certain data dictionary views. The scripts \"createUserForAssessmentWithSQLAuth.bat\" and \"createUserForAssessmentWithWindowsAuth.bat\" are supplied to create the required user and privileges. Instructions for executing it are below. Alternatively, you may use a user that already has following privileges:</p> <p>In the master database:</p> <pre><code>  GRANT VIEW SERVER STATE TO [username];\n  GRANT SELECT ALL USER SECURABLES TO [username];\n  GRANT VIEW ANY DATABASE TO [username];\n  GRANT VIEW ANY DEFINITION TO [username];\n  GRANT VIEW SERVER STATE TO [username];\n  GRANT VIEW DATABASE STATE TO [username];\n</code></pre> <p>In addition the user must also be mapped to all user databases, tempdb and master databases along with the following grant:</p> <pre><code>  use [user database name];\n  CREATE USER [username] FOR LOGIN [username];\n  GRANT VIEW DATABASE STATE TO [username];\n</code></pre>"},{"location":"user_guide/sqlserver/collection_scripts/#system-requirements","title":"System Requirements","text":"<p>The collection script depends on the following executables to be available on the machine from which it is run. The script is also expected to be run from a Windows machine in \"Administrator Mode\":</p> <pre><code>command prompt\npowershell (version 5 or greater)\nsqlcmd (version 12.0.6024.0 or greater)\n</code></pre> <p>If needed sqlcmd can be downloaded from here</p> <p>!!! note</p> <pre><code>Ensure that the `ODBC` version of `sqlcmd` is used\nEnsure that `sqlcmd` is also in your `$PATH` variable\n</code></pre>"},{"location":"user_guide/sqlserver/collection_scripts/#preparation","title":"Preparation","text":"<p>In order to begin running the Database Migration Assessment Collection process, download the collector script from here onto the host to be collected and follow the below instructions:</p> <p></p> <pre><code>- Alternative download instructions:\n    mkdir ./dbma_collector &amp;&amp; cd dbma_collector\n    wget https://github.com/GoogleCloudPlatform/database-assessment/releases/latest/download/db-migration-assessment-collection-scripts-sqlserver.zip\n\n- Unzip the install archive:\n    unzip db-migration-assessment-collection-scripts-sqlserver.zip\n\n- As of the current release, the collection scripts require a user with the SYSADMIN privilege.  An existing user may be used or one can be created using the scripts as shown below:\n\n    If an existing user with SYSADMIN privileges wil not be used, from a command prompt, execute either of the following scripts depending on what type of authentication you currently use for your SYSADMIN user.\n\n    In this example the collection user will use SQL Authentication:\n        - createUserForAssessmentWithSQLAuth.bat\n            The following parameters can be specified:\n                -serverName  ** Required\n                -port  ** Optional (Defaults to 1433)\n                -serverUserName  ** Required\n                -serverUserPass  ** Required\n                -collectionUserName  ** Required\n                -collectionUserPass  ** Optional (If not provided will be prompted)\n\n        For a Named Instance:\n            createUserForAssessmentWithSQLAuth.bat -serverName [servername\\instanceName] -port [port number] -serverUserName [existing privileged user] -serverUserPass [privileged user password] -collectionUserName [collection user name] -collectionUserPass [collection user password]\n\n        For a Default Instance:\n            createUserForAssessmentWithSQLAuth.bat -serverName [servername] -port [port number] -collectionUserName [collection user name] -collectionUserPass [collection user password]\n\n    In this example, the created user will use Windows Authentication:\n        - createUserForAssessmentWithWindowsAuth.bat\n            The following parameters can be specified:\n                -serverName  ** Required\n                -port  ** Optional (Defaults to 1433)\n                -collectionUserName  ** Required\n                -collectionUserPass  ** Optional (If not provided will be prompted)\n\n        For a Named Instance:\n            createUserForAssessmentWithWindowsAuth.bat -serverName [servername\\instanceName] -port [port number] -collectionUserName [collection user name] -collectionUserPass [collection user password]\n\n        For a Default Instance:\n            createUserForAssessmentWithWindowsAuth.bat -serverName [servername] -port [port number] -collectionUserName [collection user name] -collectionUserPass [collection user password]\n</code></pre>"},{"location":"user_guide/sqlserver/collection_scripts/#execution","title":"Execution","text":""},{"location":"user_guide/sqlserver/collection_scripts/#perfmon-requirements-optional","title":"Perfmon Requirements (Optional)","text":"<ul> <li>NOTE: Executing Perfmon is OPTIONAL. If not executed the tool will evaluate complexity of migration, but not rightsizing requirements.</li> <li> <p>NOTE: The standard perfmon collector collects every 10 minutes for 8 days.</p> </li> <li> <p>If you have your own perfmon counters capturing the following statistics or run on a SQL Server Product such as Amazon RDS or Google CloudSQL for SQL Server, skip to step b, otherwise proceed to step a.   ** The Perfmon data collection process is optional and can be safely skipped. However, there will be no right sizing information in the assessment report.   </p> <pre><code>  \\Memory\\Available MBytes\n  \\PhysicalDisk(_Total)\\Avg. Disk Bytes/Read (average disk read throughput)\n  \\PhysicalDisk(_Total)\\Avg. Disk Bytes/Write (average disk write throughput)\n  \\PhysicalDisk(_Total)\\Avg. Disk sec/Read (average time in seconds to read data from disk)\n  \\PhysicalDisk(_Total)\\Avg. Disk sec/Write (average time in seconds to write data from disk)\n  \\PhysicalDisk(_Total)\\Disk Reads/sec (disk read throughput read-iops)\n  \\PhysicalDisk(_Total)\\Disk Writes/sec (disk write throughput write-iops)\n  \\Processor(_Total)\\% Idle Time\n  \\Processor(_Total)\\% Processor Time\n  \\Processor Information(_Total)\\Processor Frequency\n  \\System\\Processor Queue Length\n  \\SQLServer:Buffer Manager\\Buffer cache hit ratio\n  \\SQLServer:Buffer Manager\\Checkpoint pages/sec\n  \\SQLServer:Buffer Manager\\Free list stalls/sec\n  \\SQLServer:Buffer Manager\\Page life expectancy\n  \\SQLServer:Buffer Manager\\Page lookups/sec\n  \\SQLServer:Buffer Manager\\Page reads/sec\n  \\SQLServer:Buffer Manager\\Page writes/sec\n  \\SQLServer:General Statistics\\User Connections\n  \\SQLServer:Memory Manager\\Memory Grants Pending\n  \\SQLServer:Memory Manager\\Target Server Memory (KB)\n  \\SQLServer:Memory Manager\\Total Server Memory (KB)\n  \\SQLServer:SQL Statistics\\Batch Requests/sec\n  \\NUMA Node Memory(_Total)\\Total MBytes\n  \\NUMA Node Memory(_Total)\\Available MBytes\n</code></pre> <p></p> </li> <li> <p>From a command prompt session in \"Administrator Mode\" on the server you would like to collect data on, execute the following command:</p> </li> <li> <p>manageSQLServerPerfmonDataset.bat   The following parameters can be specified:</p> </li> <li>-operation ** Required (create, start, stop, delete, collect, createemptyfile, help)</li> <li>-instanceType ** Required (default, named)</li> <li>-namedInstanceName ** Required if instanceType is \"named\" (should be the instance name without the server name)</li> <li>-sampleDuration ** The number of intervals that perfmon sample will run defaults to 1152 (10 minute samples for 8 days)</li> <li>-sampleInterval ** The interval that perfmon sample will run defaults to 600 (every 10 minutes)</li> </ul> <p>To create and start the perfmon collection:</p> <pre><code>    For a default instance:\n        manageSQLServerPerfmonDataset.bat -operation create -instanceType default -sampleDuration [number of intervals to sample] -sampleInterval [frequency of sample intervals in seconds]\n\n    For a named instance:\n        manageSQLServerPerfmonDataset.bat -operation create -instanceType named -namedInstanceName [instance name] -sampleDuration [number of intervals to sample] -sampleInterval [frequency of sample intervals in seconds]\n</code></pre> <p>The script will create a permon data set that will collect the above metrics at a 10 minute intervals for 8 days. The dataset will automatically stop after 8 days of collection. To get the most accurate statistics, it would be good to have this collection run over the busiest time for the server.</p> <p></p>"},{"location":"user_guide/sqlserver/collection_scripts/#perform-collection","title":"Perform Collection","text":"<ul> <li>When the perfmon dataset completes or if you would like to execute the collection sooner, execute the following command from a command prompt session in \"Administrator Mode\" on the server you would like to collect data on and return the subsequent .zip file to Google.</li> <li> <p>The collection can also be run for all user databases or a single user database. See the below examples for each scenario   </p> </li> <li> <p>runAssessment.bat   The following parameters can be specified:</p> </li> <li>-serverName **Required</li> <li>-port **Optional (Defaults to 1433)</li> <li>-database **Optional (Defaults to all user databases)</li> <li>-collectionUserName **Required</li> <li>-collectionUserPass **Required</li> <li>-ignorePerfmon **Optional (Defaults to \"false\" / Set to \"true\" to ignore perfmon collection)</li> <li>-manualUniqueId **Optional (Defaults to \"NA\" - Gives the ability the user to tag their collection with a unique name)</li> <li>-collectVMSpecs **Optional switch. See below.</li> </ul> <p>To Execute the Collection:</p> <pre><code>  For a default instance (all databases):\n    runAssessment.bat -serverName [servername] -port [port number] -collectionUserName [collection user name] -collectionUserPass [collection user password] -manualUniqueId [string]\n\n    Example (default port): runAssessment.bat -serverName MS-SERVER1 -collectionUserName sa -collectionUserPass password123 -manualUniqueId [string]\n    Example (custom port): runAssessment.bat -serverName MS-SERVER1 -port 1435 -collectionUserName sa -collectionUserPass password123 -manualUniqueId [string]\n\n  For a default instance (single database):\n    runAssessment.bat -serverName [servername] -port [port number] -database [single database name] -collectionUserName [collection user name] -collectionUserPass [collection user password] -manualUniqueId [string]\n\n    Example (default port): runAssessment.bat -serverName MS-SERVER1 -database AdventureWorks2019 -collectionUserName sa -collectionUserPass password123 -manualUniqueId [string]\n    Example (custom port): runAssessment.bat -serverName MS-SERVER1 -port 1435 -database AdventureWorks2019 -collectionUserName sa -collectionUserPass password123 -manualUniqueId [string]\n\n  For a named instance (all databases):\n    runAssessment.bat -serverName [servername\\instanceName] -port [port number] -collectionUserName [collection user name] -collectionUserPass [collection user password] -manualUniqueId [string]\n\n    Example (default port): runAssessment.bat -serverName MS-SERVER1/SQL2019 -collectionUserName sa -collectionUserPass password123 -manualUniqueId [string]\n    Example (custom port): runAssessment.bat -serverName MS-SERVER1 -port 1435 -collectionUserName sa -collectionUserPass password123 -manualUniqueId [string]\n\n  For a named instance (single database):\n    runAssessment.bat -serverName [servername\\instanceName] -port [port number] -database [single database name] -collectionUserName [collection user name] -collectionUserPass [collection user password] -manualUniqueId [string]\n\n    Example (default port): runAssessment.bat -serverName MS-SERVER1/SQL2019 -database AdventureWorks2019 -collectionUserName sa -collectionUserPass password123 -manualUniqueId [string]\n    Example (custom port): runAssessment.bat -serverName MS-SERVER1 -port 1437 -database AdventureWorks2019 -collectionUserName sa -collectionUserPass password123 -manualUniqueId [string]\n\n  For Azure SQL Database (Ignore Perfmon Collection):\n    runAssessment.bat -serverName [servername] -port [port number] -database [database name] -collectionUserName [collection user name] -collectionUserPass [collection user password] -ignorePerfmon true -manualUniqueId [string]\n\n    Example (default port): runAssessment.bat -serverName MS-SERVER1 -database AdventureWorks2019 -collectionUserName sa -collectionUserPass password123 -ignorePerfmon true -manualUniqueId [string]\n    Example (custom port): runAssessment.bat -serverName MS-SERVER1 -port 1435 -database AdventureWorks2019 -collectionUserName sa -collectionUserPass password123 -ignorePerfmon true -manualUniqueId [string]\n    Example (default port / all databases): runAssessment.bat -serverName MS-SERVER1 -collectionUserName sa -collectionUserPass password123 -ignorePerfmon true -manualUniqueId [string]\n    Example (custom port / all databases): runAssessment.bat -serverName MS-SERVER1 -port 1435 -collectionUserName sa -collectionUserPass password123 -ignorePerfmon true -manualUniqueId [string]\n\n\n\n    Notes:\n      1. Google Database Migration Assessment Data Extractor extracts data for all user databases present in the instance\n      2. Collection scripts should be executed from an \"Administrator Mode\" command prompt\n      3. When using a port to connect only provide the local host name\n      4. The manualUniqueId can be used to give the collection a unique identifier specified by the customer\n</code></pre>"},{"location":"user_guide/sqlserver/collection_scripts/#collectvmspecs","title":"CollectVMSpecs:","text":"<p>To provide rightsizing information the script attempts to connect to the host VM using the current users credentials and collect hardware specs (number of CPUs/amount of memory).</p> <p>If the current user does not have sufficient permissions, it will skip this step. To manually input the correct credentials instead when this occurs, specify the <code>-collectVMSpecs</code> switch.</p> <p>This is recommended if you plan to upload the results to the Migration Center.</p> <pre><code>    Example: runAssessment.bat -serverName MS-SERVER1 -collectionUserName sa -collectionUserPass password123 -manualUniqueId [string] -collectVMSpecs\n</code></pre>"},{"location":"user_guide/sqlserver/collection_scripts/#return-results","title":"Return Results","text":"<ul> <li>An archive of the extracted results will be created in the directory collector/output.</li> <li>The full path and file name will be displayed on completion.</li> <li>Return the listed file to Google for processing</li> </ul> <p>!!! IMPORTANT Do not modify the name or the contents of the zip file without consultation from Google.</p>"},{"location":"user_guide/sqlserver/collection_scripts/#license","title":"License","text":"<p>Copyright 2023 Google LLC</p> <p>Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at</p> <p>https://www.apache.org/licenses/LICENSE-2.0</p> <p>Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</p>"},{"location":"user_guide/sqlserver/db_user_create/","title":"Database User Scripts (Optional)","text":"<p>The collection scripts can be executed with any DBA account. Alternately, a new user with the minimum privileges required for access with the following steps. Two scripts are provided to create the user one that uses SQL Authentication and another that uses Windows Authentication.</p>"},{"location":"user_guide/sqlserver/db_user_create/#grants-required","title":"Grants Required","text":"<p>The user creation scripts will grant the appropriate permissions. If it is desired to utilize an existing user, the following grants must be granted. From the master database:</p> <pre><code>    GRANT VIEW SERVER STATE TO [username];\n    GRANT SELECT ALL USER SECURABLES TO [username];\n    GRANT VIEW ANY DATABASE TO [username];\n    GRANT VIEW ANY DEFINITION TO [username];\n    GRANT VIEW SERVER STATE TO [username];\n</code></pre> <p>For SQL Server Versions 2022 and above, the following additional permissions will be granted:</p> <pre><code>            GRANT VIEW SERVER PERFORMANCE STATE TO [username];\n            GRANT VIEW SERVER SECURITY STATE TO [username];\n            GRANT VIEW ANY PERFORMANCE DEFINITION TO [username];\n            GRANT VIEW ANY SECURITY DEFINITION TO [username];\n</code></pre> <p>For Azure SQL Database, the following grants are executed:</p> <pre><code>            ALTER SERVER ROLE ##MS_DefinitionReader## ADD MEMBER [username];\n            ALTER SERVER ROLE ##MS_SecurityDefinitionReader## ADD MEMBER [username];\n            ALTER SERVER ROLE ##MS_ServerStateReader## ADD MEMBER [username];\n</code></pre> <p>In addition the user must also be mapped to all user databases, tempdb and master databases along with the following grant:</p> <pre><code>    use [user database name];\n    CREATE USER [username] FOR LOGIN [username];\n    GRANT VIEW DATABASE STATE TO [username];\n</code></pre>"},{"location":"user_guide/sqlserver/db_user_create/#create-user","title":"Create User","text":"<p>If an existing user with SYSADMIN privileges wil not be used, from a command prompt, execute either of the following scripts depending on what type of authentication you currently use for your SYSADMIN user.</p>"},{"location":"user_guide/sqlserver/db_user_create/#sql-authentication","title":"SQL Authentication","text":"<pre><code>\n.\\createUserForAssessmentWithSQLAuth.bat\n\nThe following parameters can be specified:\n    -serverName  ** Required\n    -serverUserName  ** Required\n    -serverUserPass  ** Optional at script level.  Will be prompted if not provided\n\n        and\n\n    -collectionUserName  ** Required if a custom username will be used\n    -collectionUserPass  ** Optional at script level.  Will be prompted if not provided\n</code></pre>"},{"location":"user_guide/sqlserver/db_user_create/#windows-authentication","title":"Windows Authentication","text":"<pre><code>.\\createUserForAssessmentWithWindowsAuth.bat\n\nThe following parameters can be specified:\n    -serverName  ** Required\n    -collectionUserName  ** Required if a custom username will be used\n    -collectionUserPass  ** Optional at script level.  Will be prompted if not provided\n\n</code></pre>"},{"location":"user_guide/sqlserver/db_user_create/#notes","title":"Notes","text":""}]}